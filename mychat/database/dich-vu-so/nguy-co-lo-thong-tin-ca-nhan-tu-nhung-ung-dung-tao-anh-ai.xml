<?xml version="1.0" ?>
<document>
	<sentence>
		Nguy cơ lộ thông tin cá nhân từ những ứng dụng tạo ảnh AI.
		<word>nguy cơ</word>
		<word>lộ</word>
		<word>thông tin</word>
		<word>ứng dụng</word>
		<word>ảnh</word>
	</sentence>
	<sentence>
		Việc lộ lọt các hình ảnh tiềm ẩn nguy cơ bị hack, nếu kho ảnh rơi vào tay kẻ xấu, các đối tượng có thể dùng deepfake để tạo ra ảnh, video giả mạo cho các mục đích khác nhau, thậm chí lừa đảo….
		<word>lộ</word>
		<word>lọt</word>
		<word>hình ảnh</word>
		<word>tiềm ẩn</word>
		<word>nguy cơ</word>
		<word>hack</word>
		<word>kho</word>
		<word>ảnh</word>
		<word>rơi</word>
		<word>kẻ</word>
		<word>xấu</word>
		<word>đối tượng</word>
		<word>deepfake</word>
		<word>ảnh</word>
		<word>video</word>
		<word>giả mạo</word>
		<word>mục đích</word>
		<word>lừa đảo</word>
		<word>…</word>
	</sentence>
	<sentence>
		Chuyên gia bảo mật Vũ Ngọc Sơn, Giám đốc công nghệ Công ty An ninh mạng NCS, cho rằng việc người dùng cung cấp ảnh gốc cho các dịch vụ trí tuệ nhân tạo (AI) trên các nền tảng trực tuyến để nhận về các hình ảnh đã qua xử lý sẽ có thể phát sinh nhiều rủi ro nhất định.
		<word>chuyên gia</word>
		<word>bảo mật</word>
		<word>vũ ngọc sơn</word>
		<word>giám đốc</word>
		<word>công nghệ</word>
		<word>công ty</word>
		<word>an ninh</word>
		<word>mạng</word>
		<word>ncs</word>
		<word>cung cấp</word>
		<word>ảnh</word>
		<word>gốc</word>
		<word>dịch vụ</word>
		<word>trí tuệ</word>
		<word>nhân tạo</word>
		<word>nền tảng</word>
		<word>trực tuyến</word>
		<word>hình ảnh</word>
		<word>phát sinh</word>
		<word>rủi ro</word>
	</sentence>
	<sentence>
		Theo ông Sơn, mặc dù người dùng sau khi thu về ảnh đã xử lý và chỉ dùng các ảnh đã xử lý này để thay avatar trên mạng, tuy nhiên, các hình ảnh gốc, phần lớn là ảnh chụp cận mặt về bản chất đã được tải lên và có thể vẫn lưu trữ tại hệ thống máy chủ của các nhà cung cấp dịch vụ.
		<word>sơn</word>
		<word>mặc dù</word>
		<word>thu</word>
		<word>ảnh</word>
		<word>ảnh</word>
		<word>thay</word>
		<word>avatar</word>
		<word>mạng</word>
		<word>hình ảnh</word>
		<word>gốc</word>
		<word>ảnh</word>
		<word>chụp</word>
		<word>cận mặt</word>
		<word>bản chất</word>
		<word>tải</word>
		<word>lưu trữ</word>
		<word>hệ thống</word>
		<word>máy chủ</word>
		<word>nhà cung cấp</word>
		<word>dịch vụ</word>
	</sentence>
	<sentence>
		Việc tập trung các hình ảnh này tại một nơi sẽ tiềm ẩn nguy cơ bị lộ lọt, tấn công bởi hacker, nếu kho ảnh rơi vào tay kẻ xấu, các đối tượng có thể dùng deepfake để tạo ra ảnh và video giả mạo cho các mục đích khác nhau, thậm chí lừa đảo.
		<word>hình ảnh</word>
		<word>tiềm ẩn</word>
		<word>nguy cơ</word>
		<word>lộ</word>
		<word>lọt</word>
		<word>tấn công</word>
		<word>hacker</word>
		<word>kho</word>
		<word>ảnh</word>
		<word>rơi</word>
		<word>kẻ</word>
		<word>xấu</word>
		<word>đối tượng</word>
		<word>deepfake</word>
		<word>ảnh</word>
		<word>video</word>
		<word>giả mạo</word>
		<word>mục đích</word>
		<word>lừa đảo</word>
	</sentence>
	<sentence>
		Chuyên gia Vũ Ngọc Sơn, Giám đốc công nghệ Công ty An ninh mạng NCS.
		<word>chuyên gia</word>
		<word>vũ ngọc sơn</word>
		<word>giám đốc</word>
		<word>công nghệ</word>
		<word>công ty</word>
		<word>an ninh</word>
		<word>mạng</word>
		<word>ncs</word>
	</sentence>
	<sentence>
		“Với những người trước đó đã sử dụng các ảnh chụp cận mặt làm avatar trên mạng thì việc đưa ảnh lên để nhận về ảnh đã xử lý không phát sinh nhiều nguy cơ hơn.
		<word>“</word>
		<word>ảnh</word>
		<word>chụp</word>
		<word>cận</word>
		<word>mặt</word>
		<word>avatar</word>
		<word>mạng</word>
		<word>ảnh</word>
		<word>ảnh</word>
		<word>phát sinh</word>
		<word>nguy cơ</word>
	</sentence>
	<sentence>
		Nhưng với những người trước đó chưa dùng ảnh thật làm avatar bao giờ thì cần cân nhắc kỹ trước khi sử dụng các dịch vụ này”, ông Sơn khuyến cáo.
		<word>ảnh</word>
		<word>avatar</word>
		<word>cân nhắc</word>
		<word>kỹ</word>
		<word>dịch vụ</word>
		<word>”</word>
		<word>sơn</word>
		<word>khuyến cáo</word>
	</sentence>
	<sentence>
		Những video lừa đảo được tạo bởi công nghệ deepfake đã liên tục được cảnh báo trên các phương tiện truyền thông.
		<word>video</word>
		<word>lừa đảo</word>
		<word>công nghệ</word>
		<word>deepfake</word>
		<word>liên tục</word>
		<word>cảnh báo</word>
		<word>phương tiện</word>
		<word>truyền thông</word>
	</sentence>
	<sentence>
		Việc cung cấp ảnh cá nhân thiếu kiểm soát trên mạng là cơ sở để kẻ xấu lợi dụng hình ảnh, tạo dựng video giả mạo có hình ảnh giống thật để tiến hành lừa đảo, chiến đoạt tài sản.
		<word>cung cấp</word>
		<word>ảnh</word>
		<word>kiểm soát</word>
		<word>mạng</word>
		<word>cơ sở</word>
		<word>kẻ</word>
		<word>xấu</word>
		<word>lợi dụng</word>
		<word>hình ảnh</word>
		<word>tạo dựng</word>
		<word>video</word>
		<word>giả mạo</word>
		<word>hình ảnh</word>
		<word>tiến hành</word>
		<word>lừa đảo</word>
		<word>chiến đoạt</word>
		<word>tài sản</word>
	</sentence>
	<sentence>
		Theo ông Sơn, việc bảo vệ an toàn dữ liệu sẽ là trách nhiệm của các nhà cung cấp dịch vụ theo các quy định của pháp luật.
		<word>sơn</word>
		<word>bảo vệ</word>
		<word>an toàn</word>
		<word>dữ liệu</word>
		<word>trách nhiệm</word>
		<word>nhà cung cấp</word>
		<word>dịch vụ</word>
		<word>quy định</word>
		<word>pháp luật</word>
	</sentence>
	<sentence>
		Trong trường hợp muốn trải nghiệm các dịch vụ AI về xử lý ảnh, người dùng vẫn nên chọn các nhà cung cấp trong nước vì việc tuân thủ quy định pháp luật Việt Nam của các nhà cung cấp này sẽ cao hơn so với các nhà cung cấp không rõ nguồn gốc, không có trụ sở hoạt động tại Việt Nam.
		<word>trường hợp</word>
		<word>trải nghiệm</word>
		<word>dịch vụ</word>
		<word>ảnh</word>
		<word>nhà cung cấp</word>
		<word>tuân thủ</word>
		<word>quy định</word>
		<word>pháp luật</word>
		<word>việt nam</word>
		<word>nhà cung cấp</word>
		<word>nhà cung cấp</word>
		<word>nguồn gốc</word>
		<word>trụ sở</word>
		<word>hoạt động</word>
		<word>việt nam</word>
	</sentence>
	<sentence>
		Trong bối cảnh các tiến bộ công nghệ liên tục định hình mạng xã hội và phương tiện truyền thông đại chúng, deepfake đang trở thành mối quan ngại lớn khi số lượng những vụ lừa đảo bằng deepfake ngày càng gia tăng.
		<word>bối cảnh</word>
		<word>tiến bộ</word>
		<word>công nghệ</word>
		<word>liên tục</word>
		<word>định hình mạng</word>
		<word>xã hội</word>
		<word>phương tiện</word>
		<word>truyền thông</word>
		<word>đại chúng</word>
		<word>deepfake</word>
		<word>quan ngại</word>
		<word>số lượng</word>
		<word>vụ</word>
		<word>lừa đảo</word>
		<word>deepfake</word>
		<word>gia tăng</word>
	</sentence>
	<sentence>
		Trong một báo cáo mới đây của Kaspersky có đưa ra nhận định có nhiều tội phạm sử dụng deepfake để lừa đảo, đến mức nhu cầu sử dụng vượt xa nguồn cung các phần mềm deepfake hiện có trên thị trường.
		<word>báo cáo</word>
		<word>kaspersky</word>
		<word>nhận định</word>
		<word>tội phạm</word>
		<word>deepfake</word>
		<word>lừa đảo</word>
		<word>nhu cầu</word>
		<word>cung</word>
		<word>phần mềm</word>
		<word>deepfake</word>
		<word>hiện</word>
		<word>thị trường</word>
	</sentence>
	<sentence>
		Dự đoán, các vụ lừa đảo bằng deepfake sẽ tăng cao với nhiều hình thức đa dạng và tinh vi hơn.
		<word>dự đoán</word>
		<word>vụ</word>
		<word>lừa đảo</word>
		<word>deepfake</word>
		<word>hình thức</word>
		<word>đa dạng</word>
		<word>tinh vi</word>
	</sentence>
	<sentence>
		Từ cung cấp một video mạo danh chất lượng cao với đầy đủ dịch vụ sản xuất cho đến việc sử dụng hình ảnh người nổi tiếng trong luồng phát trực tuyến giả mạo (fake livestream) trên mạng xã hội và hứa hẹn sẽ thanh toán gấp đôi số tiền nạn nhân đã gửi họ.
		<word>cung cấp</word>
		<word>video mạo danh</word>
		<word>chất lượng</word>
		<word>đầy đủ</word>
		<word>dịch vụ</word>
		<word>sản xuất</word>
		<word>hình ảnh</word>
		<word>nổi tiếng</word>
		<word>luồng</word>
		<word>phát</word>
		<word>trực tuyến</word>
		<word>giả mạo</word>
		<word>fake</word>
		<word>livestream</word>
		<word>mạng</word>
		<word>xã hội</word>
		<word>hứa hẹn</word>
		<word>thanh toán</word>
		<word>gấp</word>
		<word>đôi</word>
		<word>tiền</word>
		<word>nạn nhân</word>
		<word>gửi</word>
	</sentence>
	<sentence>
		“Deepfake đã trở thành cơn ác mộng đối với phụ nữ và xã hội.
		<word>“</word>
		<word>deepfake</word>
		<word>ác mộng</word>
		<word>phụ nữ</word>
		<word>xã hội</word>
	</sentence>
	<sentence>
		Tội phạm mạng hiện đang khai thác trí tuệ nhân tạo để ghép khuôn mặt nạn nhân vào ảnh và video khiêu dâm cũng như trong chiến dịch tuyên truyền.
		<word>tội phạm mạng</word>
		<word>hiện</word>
		<word>khai thác</word>
		<word>trí tuệ</word>
		<word>nhân tạo</word>
		<word>ghép</word>
		<word>khuôn mặt</word>
		<word>nạn nhân</word>
		<word>ảnh</word>
		<word>video</word>
		<word>khiêu dâm</word>
		<word>chiến dịch</word>
		<word>tuyên truyền</word>
	</sentence>
	<sentence>
		Những hình thức này nhằm mục đích thao túng dư luận bằng cách phát tán thông tin sai lệch hoặc thậm chí gây tổn hại đến danh tiếng của tổ chức hoặc cá nhân.
		<word>hình thức</word>
		<word>mục đích</word>
		<word>thao túng</word>
		<word>dư luận</word>
		<word>phát tán</word>
		<word>thông tin</word>
		<word>sai lệch</word>
		<word>tổn hại</word>
		<word>danh tiếng</word>
		<word>tổ chức</word>
	</sentence>
	<sentence>
		Chúng tôi kêu gọi công chúng nâng cao cảnh giác trước mối đe dọa này”, bà Võ Dương Tú Diễm, Giám đốc khu vực Việt Nam của Kaspersky chia sẻ.
		<word>kêu gọi</word>
		<word>công chúng</word>
		<word>nâng</word>
		<word>cảnh giác</word>
		<word>đe dọa</word>
		<word>”</word>
		<word>võ dương tú diễm</word>
		<word>giám đốc</word>
		<word>khu vực</word>
		<word>việt nam</word>
		<word>kaspersky</word>
	</sentence>
	<sentence>
		Thời gian gần đây, Zalo cho phép người dùng chỉnh sửa ảnh bằng công nghệ trí tuệ nhân tạo (AI) miễn phí đã làm bùng nổ trào lưu đổi hình đại diện (avatar), quảng bá ảnh chỉnh sửa bằng AI trên các nền tảng xã hội.
		<word>zalo</word>
		<word>cho phép</word>
		<word>chỉnh sửa</word>
		<word>ảnh</word>
		<word>công nghệ trí tuệ</word>
		<word>nhân tạo</word>
		<word>miễn phí</word>
		<word>bùng nổ</word>
		<word>trào lưu đổi</word>
		<word>hình</word>
		<word>đại diện</word>
		<word>avatar</word>
		<word>quảng bá</word>
		<word>ảnh</word>
		<word>chỉnh sửa</word>
		<word>nền tảng</word>
		<word>xã hội</word>
	</sentence>
	<sentence>
		Thực trạng này dấy lên mối lo về vấn đề người dùng Internet chủ động để lọt lộ thông tin cá nhân, ảnh cá nhân, tạo cơ sở để kẻ xấu thu thập thông tin, dẫn đến nguy cơ rủi ro bị lừa đảo, chiếm đoạt tài chính trên không gian mạng.
		<word>thực trạng</word>
		<word>dấy</word>
		<word>lo</word>
		<word>internet</word>
		<word>chủ động</word>
		<word>lọt lộ</word>
		<word>thông tin</word>
		<word>ảnh</word>
		<word>cơ sở</word>
		<word>kẻ</word>
		<word>xấu</word>
		<word>thu thập</word>
		<word>thông tin</word>
		<word>nguy cơ</word>
		<word>rủi ro</word>
		<word>lừa đảo</word>
		<word>chiếm đoạt</word>
		<word>tài chính</word>
		<word>không gian</word>
		<word>mạng</word>
	</sentence>
	<sentence>
		Theo Regula, một hệ thống tham chiếu thông tin, có tới 37% doanh nghiệp trên toàn thế giới va chạm các vụ lừa đảo deepfake bằng giọng nói và 29% trở thành nạn nhân của video deepfake.
		<word>regula</word>
		<word>hệ thống</word>
		<word>tham chiếu</word>
		<word>thông tin</word>
		<word>37</word>
		<word>doanh nghiệp</word>
		<word>toàn</word>
		<word>thế giới</word>
		<word>va chạm</word>
		<word>vụ</word>
		<word>lừa đảo</word>
		<word>deepfake</word>
		<word>giọng</word>
		<word>29</word>
		<word>nạn nhân</word>
		<word>video</word>
		<word>deepfake</word>
	</sentence>
	<sentence>
		Deepfake đã trở thành mối đe dọa đối với an ninh mạng Việt Nam, nơi tội phạm mạng thường sử dụng các cuộc gọi video deepfake để mạo danh một cá nhân và vay mượn người thân, bạn bè của họ những khoản tiền lớn cho những trường hợp cấp bách.
		<word>deepfake</word>
		<word>đe dọa</word>
		<word>an ninh mạng</word>
		<word>việt nam</word>
		<word>tội phạm mạng</word>
		<word>cuộc gọi</word>
		<word>video</word>
		<word>deepfake</word>
		<word>mạo danh</word>
		<word>vay mượn</word>
		<word>người thân</word>
		<word>bạn bè</word>
		<word>khoản</word>
		<word>tiền</word>
		<word>trường hợp</word>
		<word>cấp bách</word>
	</sentence>
	<sentence>
		Hơn nữa, một cuộc gọi điện video deepfake có thể được thực hiện chỉ trong vòng một phút nên nạn nhân rất khó phân biệt giữa cuộc gọi thật và giả.
		<word>cuộc gọi</word>
		<word>điện</word>
		<word>video deepfake</word>
		<word>vòng</word>
		<word>phút</word>
		<word>nạn nhân</word>
		<word>phân biệt</word>
		<word>cuộc gọi</word>
		<word>giả</word>
	</sentence>
	<sentence>
		Mặc dù AI đang bị các tội phạm lạm dụng cho những mục đích xấu, các cá nhân và doanh nghiệp vẫn có thể tận dụng AI để nhận diện deepfake nhằm giảm thiểu xác suất thành công của các vụ lừa đảo.
		<word>mặc dù</word>
		<word>tội phạm</word>
		<word>lạm dụng</word>
		<word>mục đích</word>
		<word>xấu</word>
		<word>doanh nghiệp</word>
		<word>tận dụng</word>
		<word>nhận diện</word>
		<word>deepfake</word>
		<word>giảm thiểu</word>
		<word>xác suất</word>
		<word>thành công</word>
		<word>vụ</word>
		<word>lừa đảo</word>
	</sentence>
</document>
