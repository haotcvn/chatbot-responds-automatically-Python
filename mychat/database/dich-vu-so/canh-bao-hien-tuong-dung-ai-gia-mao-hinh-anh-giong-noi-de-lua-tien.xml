<?xml version="1.0" ?>
<document>
	<sentence>
		Cảnh báo hiện tượng dùng AI giả mạo hình ảnh, giọng nói để lừa tiền.
		<word>cảnh báo</word>
		<word>hiện tượng</word>
		<word>giả mạo</word>
		<word>hình ảnh</word>
		<word>giọng</word>
		<word>lừa</word>
		<word>tiền</word>
	</sentence>
	<sentence>
		Các đối tượng lừa đảo sử dụng AI để tạo sẵn một đoạn video giả mạo gương mặt và giọng nói của chủ tài khoản Facebook (Deepfake) để lừa đảo tài chính người dùng.
		<word>đối tượng</word>
		<word>lừa đảo</word>
		<word>sẵn</word>
		<word>đoạn</word>
		<word>video</word>
		<word>giả mạo</word>
		<word>gương mặt</word>
		<word>giọng</word>
		<word>chủ tài khoản</word>
		<word>facebook</word>
		<word>deepfake</word>
		<word>lừa đảo</word>
		<word>tài chính</word>
	</sentence>
	<sentence>
		Theo các chuyên gia, mức độ phức tạp của các kịch bản lừa đảo khi kết hợp giữa Deepfake và GPT sẽ ngày càng cao, khiến việc nhận diện lừa đảo sẽ khó khăn hơn rất nhiều.... Chiều 2/2/2024, các chuyên gia an ninh mạng Bkav đã phát đi cảnh báo về tình trạng các đối tượng lừa đảo sử dụng AI tạo hình ảnh và giọng nói giả mạo để lừa tiền.
		<word>chuyên gia</word>
		<word>mức độ</word>
		<word>phức tạp</word>
		<word>kịch bản</word>
		<word>lừa đảo</word>
		<word>kết hợp</word>
		<word>deepfake</word>
		<word>gpt</word>
		<word>nhận diện</word>
		<word>lừa đảo</word>
		<word>.... chiều</word>
		<word>2/2/2024</word>
		<word>chuyên gia</word>
		<word>an ninh</word>
		<word>mạng</word>
		<word>bkav</word>
		<word>phát</word>
		<word>đi</word>
		<word>cảnh báo</word>
		<word>đối tượng</word>
		<word>lừa đảo</word>
		<word>ai tạo</word>
		<word>hình ảnh</word>
		<word>giọng</word>
		<word>giả mạo</word>
		<word>lừa</word>
		<word>tiền</word>
	</sentence>
	<sentence>
		Nhiều người đã trở thành nạn nhân của trò lừa đảo này.
		<word>nạn nhân</word>
		<word>trò</word>
		<word>lừa đảo</word>
	</sentence>
	<sentence>
		Đơn cử như Nguyễn Thị Hương-một nhân viên văn phòng ở Hà Nội, trong một lần trò chuyện với bạn qua Facebook Messenger, người bạn đã chào và kết thúc câu chuyện nhưng đột nhiên quay lại nhắn tin, hỏi vay tiền và đề nghị chuyển tiền vào một tài khoản ngân hàng.
		<word>đơn cử</word>
		<word>nguyễn thị hương-một</word>
		<word>nhân viên</word>
		<word>văn phòng</word>
		<word>hà nội</word>
		<word>trò chuyện</word>
		<word>facebook messenger</word>
		<word>chào</word>
		<word>kết thúc</word>
		<word>câu chuyện</word>
		<word>đột nhiên</word>
		<word>nhắn tin</word>
		<word>vay</word>
		<word>tiền</word>
		<word>đề nghị</word>
		<word>tiền</word>
		<word>tài khoản</word>
		<word>ngân hàng</word>
	</sentence>
	<sentence>
		Dù tên tài khoản trùng khớp với tên bạn mình, nhân viên này nghi ngờ nên yêu cầu gọi video để xác thực.
		<word>tài khoản</word>
		<word>trùng khớp</word>
		<word>nhân viên</word>
		<word>nghi ngờ</word>
		<word>gọi</word>
		<word>video</word>
		<word>xác thực</word>
	</sentence>
	<sentence>
		Người bạn đồng ý ngay nhưng cuộc gọi chỉ kéo dài vài giây do “mạng chập chờn”, theo giải thích của người bạn.
		<word>đồng ý</word>
		<word>cuộc gọi</word>
		<word>kéo dài</word>
		<word>giây</word>
		<word>“</word>
		<word>mạng</word>
		<word>chập chờn</word>
		<word>”</word>
		<word>giải thích</word>
	</sentence>
	<sentence>
		Đã thấy mặt bạn mình trong cuộc gọi video, giọng nói cũng đúng nên chị Hương đã chuyển tiền.
		<word>mặt</word>
		<word>cuộc gọi</word>
		<word>video</word>
		<word>giọng</word>
		<word>hương</word>
		<word>tiền</word>
	</sentence>
	<sentence>
		Tuy nhiên, chỉ sau khi chuyển tiền thành công, chị mới biết mình đã mắc bẫy của hacker.
		<word>tiền</word>
		<word>thành công</word>
		<word>mắc</word>
		<word>bẫy</word>
		<word>hacker</word>
	</sentence>
	<sentence>
		Không chỉ chị Hương, nhiều nạn nhân khác là bạn bè, người thân của người bạn Hương cũng bị lừa theo cách tương tự.
		<word>hương</word>
		<word>nạn nhân</word>
		<word>bạn bè</word>
		<word>người thân</word>
		<word>hương</word>
		<word>lừa</word>
		<word>tương tự</word>
	</sentence>
	<sentence>
		Số tiền kẻ xấu lừa được từ tài khoản Facebook đó lên tới hàng chục triệu đồng.
		<word>tiền</word>
		<word>kẻ</word>
		<word>xấu</word>
		<word>lừa</word>
		<word>tài khoản</word>
		<word>facebook</word>
		<word>hàng</word>
		<word>chục</word>
		<word>triệu</word>
		<word>đồng</word>
	</sentence>
	<sentence>
		Các chuyên gia an ninh mạng Bkav cho biết, nửa cuối năm 2023, Bkav liên tục nhận được các báo cáo cũng như yêu cầu trợ giúp của nạn nhân về các vụ việc lừa đảo tương tự.
		<word>chuyên gia</word>
		<word>an ninh</word>
		<word>mạng</word>
		<word>bkav</word>
		<word>nửa</word>
		<word>2023</word>
		<word>bkav</word>
		<word>liên tục</word>
		<word>báo cáo</word>
		<word>trợ giúp</word>
		<word>nạn nhân</word>
		<word>vụ việc</word>
		<word>lừa đảo</word>
		<word>tương tự</word>
	</sentence>
	<sentence>
		Trong trường hợp của chị Hương, kẻ xấu đã kiểm soát được tài khoản Facebook nhưng không lập tức chiếm đoạt hoàn toàn mà âm thầm theo dõi, chờ cơ hội giả làm nạn nhân để hỏi vay tiền bạn bè, người thân của họ.
		<word>trường hợp</word>
		<word>hương</word>
		<word>kẻ</word>
		<word>xấu</word>
		<word>kiểm soát</word>
		<word>tài khoản</word>
		<word>facebook</word>
		<word>lập tức</word>
		<word>chiếm đoạt</word>
		<word>âm thầm</word>
		<word>theo dõi</word>
		<word>chờ</word>
		<word>giả</word>
		<word>nạn nhân</word>
		<word>vay</word>
		<word>tiền</word>
		<word>bạn bè</word>
		<word>người thân</word>
	</sentence>
	<sentence>
		Chúng sử dụng AI để tạo sẵn một đoạn video giả mạo gương mặt và giọng nói của chủ tài khoản Facebook (Deepfake).
		<word>sẵn</word>
		<word>đoạn</word>
		<word>video</word>
		<word>giả mạo</word>
		<word>gương mặt</word>
		<word>giọng</word>
		<word>chủ tài khoản</word>
		<word>facebook</word>
		<word>deepfake</word>
	</sentence>
	<sentence>
		Khi được yêu cầu gọi điện video call để chứng thực, chúng đồng ý nhận cuộc gọi nhưng sau đó nhanh chóng ngắt kết nối để tránh bị phát hiện.
		<word>gọi</word>
		<word>điện</word>
		<word>video call</word>
		<word>chứng thực</word>
		<word>đồng ý</word>
		<word>cuộc gọi</word>
		<word>nhanh chóng</word>
		<word>ngắt</word>
		<word>kết nối</word>
		<word>phát hiện</word>
	</sentence>
	<sentence>
		Các chuyên gia an ninh mạng cũng nhấn mạnh, ngay cả khi người dùng thực hiện một cuộc gọi video và thấy mặt người thân hay bạn bè, nghe đúng giọng nói của họ thì cũng không hẳn bạn đang nói chuyện với chính người đó.
		<word>chuyên gia</word>
		<word>an ninh mạng</word>
		<word>nhấn mạnh</word>
		<word>cuộc gọi</word>
		<word>video</word>
		<word>mặt</word>
		<word>người thân</word>
		<word>bạn bè</word>
		<word>giọng</word>
		<word>hẳn</word>
		<word>nói chuyện</word>
	</sentence>
	<sentence>
		Gần đây, nhiều người đã trở thành nạn nhân của các cuộc lừa đảo tài chính sử dụng Deepfake và có sự tham gia của AI tương tự.
		<word>nạn nhân</word>
		<word>lừa đảo</word>
		<word>tài chính</word>
		<word>deepfake</word>
		<word>tham gia</word>
		<word>tương tự</word>
	</sentence>
	<sentence>
		Ông Nguyễn Tiến Đạt, Tổng Giám đốc Trung tâm nghiên cứu mã độc (AntiMalware) của Bkav, cho biết khả năng thu thập và phân tích dữ liệu người dùng thông qua AI cho phép tạo ra những chiến lược lừa đảo tinh vi.
		<word>nguyễn tiến đạt</word>
		<word>tổng giám đốc</word>
		<word>trung tâm</word>
		<word>nghiên cứu</word>
		<word>mã độc</word>
		<word>antimalware</word>
		<word>bkav</word>
		<word>khả năng</word>
		<word>thu thập</word>
		<word>phân tích</word>
		<word>dữ liệu</word>
		<word>thông qua</word>
		<word>cho phép</word>
		<word>chiến lược</word>
		<word>lừa đảo</word>
		<word>tinh vi</word>
	</sentence>
	<sentence>
		Điều này cũng có nghĩa là mức độ phức tạp của các kịch bản lừa đảo khi kết hợp giữa Deepfake và GPT sẽ ngày càng cao, khiến việc nhận diện lừa đảo sẽ khó khăn hơn rất nhiều.
		<word>nghĩa</word>
		<word>mức độ</word>
		<word>phức tạp</word>
		<word>kịch bản</word>
		<word>lừa đảo</word>
		<word>kết hợp</word>
		<word>deepfake</word>
		<word>gpt</word>
		<word>nhận diện</word>
		<word>lừa đảo</word>
	</sentence>
	<sentence>
		Để không bị sập bẫy lừa đảo, Bkav khuyến cáo người dùng cần đặc biệt nâng cao cảnh giác, không cung cấp thông tin cá nhân (căn cước công dân, tài khoản ngân hàng, mã OTP…), không chuyển tiền cho người lạ qua điện thoại, mạng xã hội, các trang web có dấu hiệu lừa đảo.
		<word>sập</word>
		<word>bẫy</word>
		<word>lừa đảo</word>
		<word>bkav</word>
		<word>khuyến cáo</word>
		<word>nâng</word>
		<word>cảnh giác</word>
		<word>cung cấp</word>
		<word>thông tin</word>
		<word>căn cước</word>
		<word>công dân</word>
		<word>tài khoản</word>
		<word>ngân hàng</word>
		<word>mã otp</word>
		<word>…</word>
		<word>tiền</word>
		<word>lạ</word>
		<word>điện thoại</word>
		<word>mạng</word>
		<word>xã hội</word>
		<word>trang web</word>
		<word>dấu hiệu</word>
		<word>lừa đảo</word>
	</sentence>
	<sentence>
		Khi có yêu cầu vay/chuyển tiền vào tài khoản qua mạng xã hội, nên thực hiện các phương thức xác thực khác như gọi điện thoại hay sử dụng các kênh liên lạc khác để xác nhận lại.
		<word>vay</word>
		<word>tiền</word>
		<word>tài khoản</word>
		<word>mạng</word>
		<word>xã hội</word>
		<word>phương thức</word>
		<word>xác thực</word>
		<word>gọi</word>
		<word>điện thoại</word>
		<word>kênh</word>
		<word>liên lạc</word>
		<word>xác nhận</word>
	</sentence>
	<sentence>
		Dự báo về tình hình an ninh mạng năm 2024, các chuyên gia an ninh mạng Bkav cho hay, sự phát triển nhanh chóng của AI không chỉ mang lại những lợi ích rõ ràng mà còn tạo ra những nguy cơ đáng kể cho an ninh mạng.
		<word>dự báo</word>
		<word>tình hình</word>
		<word>an ninh</word>
		<word>mạng</word>
		<word>2024</word>
		<word>chuyên gia</word>
		<word>an ninh</word>
		<word>mạng</word>
		<word>bkav</word>
		<word>phát triển</word>
		<word>nhanh chóng</word>
		<word>lợi ích</word>
		<word>rõ ràng</word>
		<word>mà còn</word>
		<word>nguy cơ</word>
		<word>an ninh mạng</word>
	</sentence>
	<sentence>
		Thách thức lớn nhất đối diện với công nghệ AI ngày nay là lừa đảo và tấn công có chủ đích APT, với mức độ ngày càng phức tạp của các kịch bản lừa đảo, đặc biệt khi kết hợp giữa Deepfake và GPT.
		<word>thách thức</word>
		<word>đối diện</word>
		<word>công nghệ</word>
		<word>ngày nay</word>
		<word>lừa đảo</word>
		<word>tấn công</word>
		<word>chủ</word>
		<word>đích apt</word>
		<word>mức độ</word>
		<word>phức tạp</word>
		<word>kịch bản</word>
		<word>lừa đảo</word>
		<word>kết hợp</word>
		<word>deepfake</word>
		<word>gpt</word>
	</sentence>
	<sentence>
		Khả năng thu thập và phân tích dữ liệu người dùng thông qua AI cho phép tạo ra những chiến lược lừa đảo tinh vi, khiến việc nhận diện lừa đảo sẽ khó khăn hơn đối với người dùng.
		<word>khả năng</word>
		<word>thu thập</word>
		<word>phân tích</word>
		<word>dữ liệu</word>
		<word>thông qua</word>
		<word>cho phép</word>
		<word>chiến lược</word>
		<word>lừa đảo</word>
		<word>tinh vi</word>
		<word>nhận diện</word>
		<word>lừa đảo</word>
	</sentence>
</document>
